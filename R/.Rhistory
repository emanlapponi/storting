}
else{
resa <- optim(par=c(params$omega[i],params$alpha[i]),
fn=llik_alpha_omega,
y=as.numeric(dta[i,]),
b=params$b,
psi=params$psi)
params$omega[i] <- resa$par[1]
params$alpha[i] <- resa$par[2]
params$min1[i] <- -1.00*resa$value
ifelse(resa$convergence!=0,print("Warning: Optim Failed to Converge!"),NA)
}
}
flush.console()
# ESTIMATE PSI AND BETA
if(printsum==TRUE){
cat("\tUpdating psi and beta..\n")
}
for (j in 1:W) {
resb <- optim(par=c(params$b[j],params$psi[j]),
fn=llik_psi_b,
y=dta[,j],
omega=params$omega,
alpha=params$alpha,
sigma=sigma
)
params$b[j] <- resb$par[1]
params$psi[j] <- resb$par[2]
params$min2[j] <- -1.00*resb$value
ifelse(resa$convergence!=0,print("Warning: Optim Failed to Converge!"),NA)
}
flush.console()
# Calculate Log-Likelihood
maxllik[iter]<-sum(params$min2)
diffparam<-mean(abs(params$omega-omegaprev)) # difference between current and previous estimate for omega
ll.words[,iter]<-params$min2
diff.ll.words<-(ll.words[,iter]-ll.words[,iter-1])
diffllik<-sum(diff.ll.words)/abs(maxllik[iter])
#print(sum(diff.ll.words))
#print(abs(maxllik[iter]))
if(printsum==TRUE){
cat("\tConvergence of LL: ",diffllik,"\n")}
params$diffllik[iter-1]<-diffllik
params$diffparam[iter-1]<-diffparam
params$diffparam.last<-diffparam
params$maxllik[iter-1]<-maxllik[iter]
params$iter<-iter-1
iter<-iter+1
}
params$diffllik[1]<-NA
return(params)
}
#  Run the algorithm
est <- rockingpoisson(dta,tol,sigma,fixdoc=fixdoc)
}
cat("======================================\n")
cat("WORDFISH ML Estimation finished.\n")
cat("======================================\n\n")
# Write output
output.documents <-cbind(est$omega,est$alpha)
rownames(output.documents)<-rownames(dta)
colnames(output.documents)<-c("omega","alpha")
output.words<-cbind(est$b,est$psi)
rownames(output.words) <-words
colnames(output.words) <-c("b","psi")
# Write estimation output file
# Include: Log-likelihood, iterations, number of words, number of documents
output.estimation<-cbind(nword,nparty,est$iter,sum(est$min2),est$conv,est$diffparam.last)
colnames(output.estimation)<-c("Words","Documents","Iterations","Log-Likelihood","Convergence Criterion","Difference in X")
if(writeout==TRUE){
write.table(output.documents,file=paste(output,"documents.csv",sep="_"))
write.table(output.words, file=paste(output,"words.csv",sep="_"))
write.table(output.estimation, file=paste(output,"estimation.csv",sep="_"))
}
###########################
# Parametric Bootstrap Code
###########################
bootstrap<-function(nsim,output.documents,output.words,nparty,nword) {
cat("STARTING PARAMETRIC BOOTSTRAP\n")
# input alpha and omega from estimation
alpha.omega<-output.documents
# input psis and betas from estimation
psi.beta<-output.words
# Create matrix of results.
output.se.omega<-matrix(0,nparty,nsim)
output.se.b<-matrix(0,nword,nsim)
alpha<-alpha.omega[,2]
omega<-alpha.omega[,1]
psi<-psi.beta[,2]
b<-psi.beta[,1]
# create data matrix
dtasim<-matrix(1,nrow=nparty,ncol=nword)
cat("======================================\n")
cat("Now running", nsim,"bootstrap trials.\n")
cat("======================================\n")
cat("Simulation ")
for (k in 1:nsim){
cat(k,"...")
# Generate new data using lambda
for (i in 1:nparty) {
dtasim[i,]<-rpois(nword,exp(psi+alpha[i]+b*omega[i]))
}
alphastart<-alpha+rnorm(length(alpha.omega[,1]),mean=0,sd=(sd(alpha.omega[,2])/2))
omegastart<-omega+rnorm(length(alpha.omega[,1]),mean=0,sd=(sd(alpha.omega[,1])/2))
psistart<-psi+rnorm(length(psi.beta[,1]),mean=0,sd=(sd(psi.beta[,2])/2))
bstart<-b+rnorm(length(psi.beta[,1]),mean=0,sd=(sd(psi.beta[,1])/2))
params<-list(alpha=alphastart,omega=omegastart,psi=psistart,b=bstart)
if(fixtwo==FALSE){
est <- rockingpoisson(dtasim,tol,sigma,params=params,dir=dir,printsum=FALSE)
}
else{
est <- rockingpoisson(dtasim,tol,sigma,params=params,fixdoc=fixdoc,printsum=FALSE)
}
# Store omegas
output.se.omega[,k]<-est$omega
# Store Bs
output.se.b[,k]<-est$b
}
conf.documents<-matrix(0,nparty,4)
colnames(conf.documents)<-c("LB","UB","Omega: ML","Omega: Sim Mean")
rownames(conf.documents)<-rownames(dta)
for (i in 1:nparty) {
conf.documents[i,1]<-quantile(output.se.omega[i,],0.025)
conf.documents[i,2]<-quantile(output.se.omega[i,],0.975)
conf.documents[i,3]<-omega[i]
conf.documents[i,4]<-mean(output.se.omega[i,])
}
#CI for word weights
conf.words<-matrix(0,nword,4)
colnames(conf.words)<-c("LB","UB","B: ML","B: Sim Mean")
rownames(conf.words)<-words
for (i in 1:nword) {
conf.words[i,1]<-quantile(output.se.b[i,],0.025)
conf.words[i,2]<-quantile(output.se.b[i,],0.975)
conf.words[i,3]<-b[i]
conf.words[i,4]<-mean(output.se.b[i,])
}
return(list(conf.documents=conf.documents,conf.words=conf.words))
}
if(boots==TRUE){
bootresult<-bootstrap(nsim,output.documents,output.words,nparty,nword)
ci.documents<-bootresult$conf.documents
ci.words<-bootresult$conf.words
if(writeout==TRUE){
write.table(ci.words,file=paste(output,"words_95_ci.csv",sep="_"))
write.table(ci.documents,file=paste(output,"documents_95_ci.csv",sep="_"))
}
}
if(boots==F){
ci.documents<-NULL
ci.words<-NULL
}
cat("Finished!\n")
return(list(documents=output.documents,words=output.words,diffllik=est$diffllik,diffomega=est$diffparam,maxllik=est$maxllik,estimation=output.estimation,ci.documents=ci.documents,ci.words=ci.words))
}
library(tm);library(parallel);library(SnowballC);library(stringi);library(ggplot2)
library(dplyr)
theme_set(theme_bw())
taler <- read.csv("../../taler/id_taler_meta.csv")
taler$word_count <- stri_count_words(taler$text)
taler_long <- taler %>%
filter(word_count > 250) %>%
group_by(rep_id, party_id, parl_session) %>%
summarise(text = paste(text, collapse = " "))
cores <- detectCores()-2
corpus <- Corpus(VectorSource(taler_long$text))
corpus <- tm_map(corpus, content_transformer(tolower), mc.cores = cores)
corpus <- tm_map(corpus, content_transformer(removeNumbers), mc.cores = cores)
corpus <- tm_map(corpus, content_transformer(removePunctuation), mc.cores = cores)
corpus <- tm_map(corpus, stripWhitespace, mc.cores = cores)
corpus <- tm_map(corpus, removeWords, stopwords("nor"), mc.cores = cores)
corpus <- tm_map(corpus, stemDocument,language = "nor", mc.cores = cores)
termMat <- TermDocumentMatrix(corpus)
termMat <- removeSparseTerms(termMat, .95)
View(taler_long)
install.packages("austin")
devtools::install_github("conjugateprior/austin")
install.packages("devtools")
devtools::install_github("conjugateprior/austin")
rm(wordfish())
rm(wordfish
)
library(austin)
freqMat <- wfm(as.matrix(termMat))
View(freqMat)
ncol(freqMat)
colnames(freqMat)
colnames(freqMat) <- paste(taler_long$rep_id, taler_long$parl_session)
colnames(freqMat)
View(taler_long)
results <- wordfish(freqMat, dir = c(17, 32))
summary(results)
st_wf <- summary(results)$scores
names(results)
names(results$docs)
names(results$dir)
names(results$data)
names(summary(results)$scores)
freqMat <- wfm(as.matrix(termMat))
colnames(freqMat) <- paste(taler_long$rep_id, taler_long$party_id, taler_long$parl_session)
results <- wordfish(freqMat, dir = c(68, 51))
st_wf <- summary(results)$scores
View(st_wf)
rownames(st_wf)[1:10]
st_wf$rep_id <- sapply(strsplit(rownames(st_wf), " "), "[[", 1)
st_wf$party_id <- sapply(strsplit(rownames(st_wf), " "), "[[", 2)
st_wf$parl_session <- sapply(strsplit(rownames(st_wf), " "), "[[", 3)
View(st_wf)
parties <- st_wf %>%
group_by(party_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = estimate, color = party_id))+
geom_path
ggplot(parties, aes(x = parl_session, y = estimate, color = party_id))+
geom_path()
ggplot(parties, aes(x = parl_session, y = est, color = party_id))+
geom_path()
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()
View(parties)
parties <- st_wf %>%
filter(party_id == "SV" | party_id == "FrP") %>%
group_by(party_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()
parties <- st_wf %>%
filter(party_id == "AP" | party_id == "FrP") %>%
group_by(party_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()
parties <- st_wf %>%
filter(party_id == "A" | party_id == "FrP") %>%
group_by(party_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
parties <- st_wf %>%
filter(party_id == "A" | party_id == "FrP") %>%
group_by(party_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()
parties <- st_wf %>%
filter(party_id == "A" | party_id == "SV") %>%
group_by(party_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()
st_wf[which(st_wf$Estimate == max(st_wf$Estimate)), ]
st_wf[which(st_wf$Estimate == min(st_wf$Estimate)), ]
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()+
scale_color_manual(values = c("darkblue", "darkred"))
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()+
scale_color_manual(values = c("darkblue", "brown1"))
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()+
scale_color_manual(values = c("darkblue", "brown1"))+
theme_classic()
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()+
scale_color_manual(values = c("darkblue", "brown1"))+
theme_classic()+
labs(y = "Wordfish estimate")
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()+
scale_color_manual(values = c("darkblue", "brown1"))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
parties <- st_wf %>%
filter(party_id == "FrP" | party_id == "SV") %>%
group_by(party_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()+
scale_color_manual(values = c("darkblue", "brown1"))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
parties <- st_wf %>%
filter(party_id == "FrP" | party_id == "H") %>%
group_by(party_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()+
scale_color_manual(values = c("darkblue", "brown1"))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
parties <- st_wf %>%
filter(rep_id == "CT" | party_id == "ALYS") %>%
group_by(rep_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = party_id, color = party_id))+
geom_path()
ggplot(parties, aes(x = parl_session, y = est, group = rep_id, color = rep_id))+
geom_path()
parties
taler[which(taler$rep_id == "ALYS"), 1:33]
cat("\014");gc()
parties <- st_wf %>%
filter(rep_id == "CT" | party_id == "KAAN") %>%
group_by(rep_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
parties <- st_wf %>%
filter(rep_id == "CT" | rep_id == "KAAN") %>%
group_by(rep_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = rep_id, color = rep_id))+
geom_path()+
scale_color_manual(values = c("darkblue", "brown1"))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
parties <- st_wf %>%
filter(rep_id == "CT" | rep_id == "ALYS") %>%
group_by(rep_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = rep_id, color = rep_id))+
geom_path()+
scale_color_manual(values = c("darkblue", "brown1"))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
rm(list=ls());cat("\014");gc()
rm(list=ls());cat("\014");gc()
library(tm);library(parallel);library(SnowballC);library(stringi);library(ggplot2)
library(dplyr);library(austin)
theme_set(theme_bw())
taler <- read.csv("../../taler/id_taler_meta.csv")
taler$word_count <- stri_count_words(taler$text)
taler_long <- taler %>%
filter(word_count > 250) %>%
group_by(rep_id, party_id, parl_session) %>%
summarise(text = paste(text, collapse = " "))
cores <- detectCores()-2
corpus <- Corpus(VectorSource(taler_long$text))
corpus <- tm_map(corpus, content_transformer(tolower), mc.cores = cores)
corpus <- tm_map(corpus, content_transformer(removeNumbers), mc.cores = cores)
corpus <- tm_map(corpus, content_transformer(removePunctuation), mc.cores = cores)
corpus <- tm_map(corpus, stripWhitespace, mc.cores = cores)
corpus <- tm_map(corpus, removeWords, stopwords("nor"), mc.cores = cores)
corpus <- tm_map(corpus, stemDocument,language = "nor", mc.cores = cores)
termMat <- TermDocumentMatrix(corpus)
termMat <- removeSparseTerms(termMat, .95)
freqMat <- wfm(as.matrix(termMat))
colnames(freqMat) <- paste(taler_long$rep_id, taler_long$party_id, taler_long$parl_session)
results <- wordfish(freqMat, dir = c(68, 51))
st_wf <- summary(results)$scores
st_wf$rep_id <- sapply(strsplit(rownames(st_wf), " "), "[[", 1)
st_wf$party_id <- sapply(strsplit(rownames(st_wf), " "), "[[", 2)
st_wf$parl_session <- sapply(strsplit(rownames(st_wf), " "), "[[", 3)
save(st_wf, file = "../../wordfishtest.rda")
View(st_wf)
parties <- st_wf %>%
filter(rep_id == "CT" | rep_id == "ALYS") %>%
group_by(rep_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = rep_id, color = rep_id))+
geom_path()+
scale_color_manual(values = c("darkblue", "brown1"))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
ggplot(parties, aes(x = parl_session, y = est, group = rep_id, color = rep_id))+
geom_path()+
scale_color_manual(values = rev(c("darkblue", "brown1")))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
taler$rep_id[which(taler$rep_name == "Per Sandberg")]
parties <- st_wf %>%
filter(rep_id == "CT" | rep_id == "PES") %>%
group_by(rep_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = rep_id, color = rep_id))+
geom_path()+
scale_color_manual(values = rev(c("darkblue", "brown1")))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
parties <- st_wf %>%
filter(rep_id == "PES" | rep_id == "ALYS") %>%
group_by(rep_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = rep_id, color = rep_id))+
geom_path()+
scale_color_manual(values = rev(c("darkblue", "brown1")))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
load("../../wordfishtest.rda")
parties <- st_wf %>%
filter(rep_id == "PES" | rep_id == "ALYS") %>%
group_by(rep_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = rep_id, color = rep_id))+
geom_path()+
scale_color_manual(values = rev(c("darkblue", "brown1")))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
parties <- st_wf %>%
filter(rep_id == "PES" | rep_id == "ALYS") %>%
group_by(rep_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = rep_id, color = rep_id))+
geom_path()+
scale_color_manual(values = rev(c("darkblue", "brown1")))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
library(tm);library(parallel);library(SnowballC);library(stringi);library(ggplot2)
library(dplyr);library(austin)
parties <- st_wf %>%
filter(rep_id == "PES" | rep_id == "ALYS") %>%
group_by(rep_id, parl_session) %>%
summarise(est = mean(Estimate, na.rm = TRUE))
ggplot(parties, aes(x = parl_session, y = est, group = rep_id, color = rep_id))+
geom_path()+
scale_color_manual(values = rev(c("darkblue", "brown1")))+
theme_classic()+
labs(y = "Wordfish estimate", x = NULL, color = "Party")
View(st_wf)
View(parties)
rm(list = ls());cat("\014");gc()
# install.packages("./Data/uacd/uacd_0.14.tar.gz", repos = NULL)
library(stringr);library(uacd);library(dplyr);library(rvest);library(parallel);library(zoo);library(gsubfn)
library(XML)
ncores <- detectCores()-2
source("./Scripts/session_prep.R")
source("./Scripts/cab_prep.R")
source("./Scripts/rep_df.R")
source("./Scripts/seats_prep.R")
source("./Scripts/taler_prep.R")
source("./Scripts/bios.R")
# source("./Scripts/bios_struc.R")
wrapup <- expand.grid(cabinet_short = norCabinet$cabinet_short, party_id = levels(factor(reps$party_id)))
wrapup <- merge(x = wrapup, y = norCabinet, by = "cabinet_short", all.x = TRUE)
wrapup$role <- NA
for(i in 1:nrow(wrapup)){
wrapup$role[i] <- ifelse(grepl(wrapup$party_id[i], wrapup$CabinetPartiesNor[i])==TRUE, "Cabinet", "Opposition")
}
wrapup$role <- ifelse(grepl("Stoltenberg", wrapup$cabinet_short) & wrapup$party_id == "V", "Opposition", wrapup$role)
fullname <- unique(reps[, c("party_id", "party_name", "session")])
wrapup <- merge(x = wrapup, y = fullname, by = c("party_id", "session"))
wrapup <- merge(x = wrapup, y = seats, by = c("party_name", "session"))
wrapup <- arrange(wrapup, session, cabinet_short, party_id)
wrapup <- wrapup[, c("party_id", "session", "seats", "role", "composition",
"cabinet_short", "From", "To", "party_name",
"parl_size", "seats_lagting", "seats_odelsting")]
wrapup$role <- ifelse(wrapup$party_id == "KrF" & wrapup$cabinet_short == "Solberg I", "Support", wrapup$role)
wrapup$role <- ifelse(wrapup$party_id == "V" & wrapup$cabinet_short == "Solberg I", "Support", wrapup$role)
wrapup <- merge(x = reps, y = wrapup, by = c("party_id", "cabinet_short", "session", "party_name"), all.x = TRUE)
rm(reps, fullname, norCabinet, seats, i)
wrapup$name <- paste(wrapup$first_name, wrapup$last_name)
wrapup <- wrapup[, c("id", "first_name", "last_name", "name",
"party_id", "party_name", "role", "seats",
"cabinet_short", "From", "To", "composition",
"gender", "birth", "death", "fylke_id", "fylke_name",
"session", "parl_size", "seats_lagting", "seats_odelsting"), ]
names(wrapup) <- c("rep_id", "rep_first_name", "rep_last_name", "rep_name",
"party_id", "party_name", "party_role", "party_seats",
"cabinet_short", "cabinet_start", "cabinet_end", "cabinet_composition",
"rep_gender", "rep_birth", "rep_death", "rep_fylke_id", "rep_fylke_name",
"parl_session", "parl_size", "party_seats_lagting", "party_seats_odelsting")
cab_name_date <- wrapup %>%
group_by(cabinet_short) %>%
summarise(cabinet_start = cabinet_start[1],
cabinet_end = cabinet_end[1])
taler$cabinet_short <- NA
cab_name_by_date <- function(cabinet_name){
new <- ifelse(taler$date >= cab_name_date$cabinet_start[which(cab_name_date$cabinet_short == cabinet_name)] &
taler$date <= cab_name_date$cabinet_end[which(cab_name_date$cabinet_short == cabinet_name)],
cabinet_name, taler$cabinet_short)
return(new)
}
taler$cabinet_short <- cab_name_by_date("Bondevik I")
taler$cabinet_short <- cab_name_by_date("Bondevik II")
taler$cabinet_short <- cab_name_by_date("Stoltenberg I")
taler$cabinet_short <- cab_name_by_date("Stoltenberg II")
taler$cabinet_short <- cab_name_by_date("Stoltenberg III")
taler$cabinet_short <- cab_name_by_date("Solberg I")
rm(cab_name_date)
party_vars <- c("party_id", "party_name", "party_role", "party_seats", "party_seats_lagting", "party_seats_odelsting",
"cabinet_short", "cabinet_start", "cabinet_end", "cabinet_composition",
"parl_session", "parl_size")
rep_vars <- c("rep_id", "rep_first_name", "rep_last_name", "rep_gender", "rep_birth", "rep_death")
wrapup_rep <- unique(wrapup[, c(setdiff(colnames(wrapup), party_vars), "party_id")])
wrapup_party <- unique(wrapup[, party_vars])
wrapup_party$party_id <- as.character(wrapup_party$party_id)
all <- all[, c("rep_id", "rep_first_name", "rep_last_name", "rep_name", "rep_birth", "rep_death")]
bios <- merge(x = bios, y = all, by = "rep_id", all.x = TRUE)
bios <- merge(x = bios, y = unique(wrapup_rep[, c("rep_id", "rep_gender")]), by = c("rep_id"), all.x = TRUE)
bios <- bios[, c("rep_id", "rep_first_name", "rep_last_name", "rep_name", "party_id", "rep_gender",
"parl_session", "rep_from", "rep_to", "type", "county", "list_number",
"rep_birth", "rep_death")]
bios <- arrange(bios, rep_id, rep_from)
rm(all, sessions_df)
taler_meta <- merge(x = taler, y = wrapup_party, by = c("cabinet_short", "party_id"), all.x = TRUE)
taler_meta <- merge(x = taler_meta, y = bios,
by = c("rep_name", "party_id", "parl_session"),
all.x = TRUE)
taler_meta <- taler_meta[, c("rep_id", "rep_first_name", "rep_last_name", "rep_name", "rep_from", "rep_to",
"type", "county", "list_number",
"party_id", "party_name", "party_role", "party_seats",
"cabinet_short", "cabinet_start", "cabinet_end", "cabinet_composition",
"rep_gender", "rep_birth", "rep_death", #"rep_fylke_id", "rep_fylke_name",
"parl_session", "parl_size", "party_seats_lagting", "party_seats_odelsting",
"transcript", "order", "session", "time", "date", "title", "text"), ]
taler_meta <- arrange(taler_meta, rep_name, date)
#########
write.csv(taler_meta, "../../taler/taler_meta.csv", row.names = FALSE)
#########
system("scp ../../taler/id_taler_meta.csv martigso@login.uio.no")
setdiff("text", names(taler_meta))
setdiff(names(taler_meta), "text")
taler_notext <- taler_meta[,setdiff(names(taler_meta), "text")]
write.csv(taler_meta, "../../taler/taler_notext.csv", row.names = FALSE)
View(taler_notext)
write.csv(taler_notext, "../../taler/taler_notext.csv", row.names = FALSE)
